{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stein/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from reaction import get_reaction_center, Reaction, single_step_synthesis, convert_product_and_reactant, single_step_synthesis_v2\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from create_data import clean_mapped_num, extract_mapped_reaction, save_reaction_center\n",
    "from data import make_useful_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义数据位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder_path = \"final_csv/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取反应中心"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216965\n"
     ]
    }
   ],
   "source": [
    "mapped_reaction_list, reaction_smiles_list = extract_mapped_reaction(file_path=data_folder_path+'/'+\"first_mapped_reaction.smi\")\n",
    "print(len(mapped_reaction_list))\n",
    "dataframe = save_reaction_center(mapped_reaction_list, save_csv=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清理map num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataframe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0fd1c95dde2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreaction_center_radius_smiles0\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reaction_center_radius_smiles0'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#radius为0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreaction_center_radius_smiles1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reaction_center_radius_smiles1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#radius为1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreaction_center_radius_smiles2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'reaction_center_radius_smiles2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#radius为2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreaction_center_smiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reaction_center_smiles\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataframe' is not defined"
     ]
    }
   ],
   "source": [
    "reaction_center_radius_smiles0 =  dataframe['reaction_center_radius_smiles0'] #radius为0\n",
    "reaction_center_radius_smiles1 = dataframe['reaction_center_radius_smiles1'] #radius为1\n",
    "reaction_center_radius_smiles2 = dataframe['reaction_center_radius_smiles2'] #radius为2\n",
    "reaction_center_smiles_list = dataframe[\"reaction_center_smiles\"]\n",
    "\n",
    "#定义list用来储存clean过之后的数据\n",
    "clean_reaction_center_radius_smiles0 = []\n",
    "clean_reaction_center_radius_smarts0 = []\n",
    "clean_reaction_center_radius_smiles1 = []\n",
    "clean_reaction_center_radius_smarts1 = []\n",
    "clean_reaction_center_radius_smiles2 = []\n",
    "clean_reaction_center_radius_smarts2 = []\n",
    "\n",
    "for index, synthesis_smiles in enumerate(reaction_center_radius_smiles0):\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    clean_reaction_rule_radius_smiles, clean_reaction_rule_radius_smarts = clean_mapped_num(synthesis_smiles)\n",
    "    clean_reaction_center_radius_smiles0.append(clean_reaction_rule_radius_smiles)\n",
    "    clean_reaction_center_radius_smarts0.append(clean_reaction_rule_radius_smarts)\n",
    "\n",
    "for index, synthesis_smiles in enumerate(reaction_center_radius_smiles1):\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    clean_reaction_rule_radius_smiles, clean_reaction_rule_radius_smarts = clean_mapped_num(synthesis_smiles)\n",
    "    clean_reaction_center_radius_smiles1.append(clean_reaction_rule_radius_smiles)\n",
    "    clean_reaction_center_radius_smarts1.append(clean_reaction_rule_radius_smarts)\n",
    "\n",
    "for index, synthesis_smiles in enumerate(reaction_center_radius_smiles2):\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    clean_reaction_rule_radius_smiles, clean_reaction_rule_radius_smarts = clean_mapped_num(synthesis_smiles)\n",
    "    clean_reaction_center_radius_smiles2.append(clean_reaction_rule_radius_smiles)\n",
    "    clean_reaction_center_radius_smarts2.append(clean_reaction_rule_radius_smarts)\n",
    "\n",
    "\n",
    "clean_reaction_center_smiles = [] \n",
    "clean_reaction_center_smarts = []\n",
    "for index, synthesis_smiles in enumerate(reaction_center_smiles_list):\n",
    "    if index % 100 == 0:\n",
    "        print (index)\n",
    "    clean_reaction_rule_smiles, clean_reaction_rule_smarts = clean_mapped_num(synthesis_smiles)\n",
    "    clean_reaction_center_smiles.append(clean_reaction_rule_smiles)\n",
    "    clean_reaction_center_smarts.append(clean_reaction_rule_smarts)\n",
    "dataframe['clean_reaction_center_radius_smiles0'] = clean_reaction_center_radius_smiles0\n",
    "dataframe['clean_reaction_center_radius_smiles1'] = clean_reaction_center_radius_smiles1\n",
    "dataframe['clean_reaction_center_radius_smiles2'] = clean_reaction_center_radius_smiles2\n",
    "dataframe[\"clean_reaction_center_radius_smarts0\"] = clean_reaction_center_radius_smarts0\n",
    "dataframe[\"clean_reaction_center_radius_smarts1\"] = clean_reaction_center_radius_smarts1\n",
    "dataframe[\"clean_reaction_center_radius_smarts2\"] = clean_reaction_center_radius_smarts2\n",
    "print(\"clean_reaction_center_radius_smarts2\",clean_reaction_center_radius_smarts2)\n",
    "\n",
    "dataframe['clean_reaction_center_smiles'] = clean_reaction_center_smiles\n",
    "dataframe['clean_reaction_center_smarts'] = clean_reaction_center_smarts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 我们仅仅使用 smarts 信息\n",
    "#### expandnetwork 的数据用的是radius为0时的数据\n",
    "#### rolloutnetwork 的数据用的是radius为1时的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 提取出现过occurance_threshold次的反应（原文 rollout network 的出现阀值是50）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule_filter(labels, occurance_threshold = 2):\n",
    "    count = np.bincount(labels)\n",
    "    coverage_rate = count[count>=occurance_threshold].sum()/len(labels)\n",
    "    print(\"coverage_rate\", coverage_rate)\n",
    "    keeped_labels = np.where(count>=occurance_threshold)[0]\n",
    "    the_filter = np.array([labels[i] in keeped_labels for i in range(len(labels))])\n",
    "    return the_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    smart1_filter = []\n",
    "    smart2_filter = []\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    smarts1 = data.clean_reaction_center_radius_smarts0.values\n",
    "    smarts2 = data.clean_reaction_center_radius_smarts1.values\n",
    "    for i in range(len(smarts1)):\n",
    "        if smarts1[i][:2] == \">>\":\n",
    "            smart1_filter.append(False)\n",
    "        else:\n",
    "            smart1_filter.append(True)\n",
    "        if smarts2[i][:2] == \">>\":\n",
    "            smart2_filter.append(False)\n",
    "        else:\n",
    "            smart2_filter.append(True)\n",
    "    smart1_filter = np.array(smart1_filter)\n",
    "    smart2_filter = np.array(smart2_filter)\n",
    "    new_data = data.iloc[np.logical_and(smart1_filter, smart2_filter)]\n",
    "    new_data.reset_index(drop=True, inplace=True)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_useful_data(data, save_path):\n",
    "    data = clean_data(data)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    lbl0 = LabelEncoder()\n",
    "    lbl1 = LabelEncoder()\n",
    "    lbl_exp = LabelEncoder()\n",
    "    lbl_roll = LabelEncoder()\n",
    "    expand_rule_labels = lbl0.fit_transform(data.clean_reaction_center_radius_smarts0.values)\n",
    "    rollout_rule_labels = lbl1.fit_transform(data.clean_reaction_center_radius_smarts1.values)\n",
    "    expand_rule_filter = rule_filter(labels=expand_rule_labels, occurance_threshold=2)\n",
    "    rollout_rule_filter = rule_filter(labels=rollout_rule_labels, occurance_threshold=3)\n",
    "    data_expand_network = data[expand_rule_filter]\n",
    "    data_expand_network.reset_index(drop=True, inplace=True)\n",
    "    oexpand_rule_labels = lbl0.inverse_transform(expand_rule_labels[expand_rule_filter])\n",
    "    lbl_exp.fit_transform(oexpand_rule_labels)\n",
    "    data_expand_network[\"y\"] = lbl_exp.fit_transform(oexpand_rule_labels)\n",
    "    del data_expand_network[\"clean_reaction_center_radius_smarts1\"]  \n",
    "    data_expand_network.columns = [\"mapped_reaction_smiles\", \"reaction_center_radius0\", 'y']\n",
    "\n",
    "    data_rollout_network = data[rollout_rule_filter]\n",
    "    data_rollout_network.reset_index(drop=True, inplace=True)\n",
    "    orollout_rule_labels = lbl1.inverse_transform(rollout_rule_labels[rollout_rule_filter])\n",
    "    data_rollout_network[\"y\"] = lbl_roll.fit_transform(orollout_rule_labels)\n",
    "    del data_rollout_network[\"clean_reaction_center_radius_smarts0\"]\n",
    "    data_rollout_network.columns = [\"mapped_reaction_smiles\", \"reaction_center_radius1\", 'y']\n",
    "\n",
    "    data_expand_network.to_csv(os.path.join(save_path, \"data_expand_network.csv\"), index=False)\n",
    "    data_rollout_network.to_csv(os.path.join(save_path, \"data_rollout_network.csv\"), index = False)\n",
    "\n",
    "    np.save(os.path.join(save_path, \"expand_rule_label_encoder.npy\"), lbl_exp.classes_)\n",
    "    np.save(os.path.join(save_path, \"rollout_rule_label_encoder.npy\"), lbl_roll.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe[\"mapped_reaction_smiles\",\"clean_reaction_center_radius_smarts0\",\"clean_reaction_center_radius_smarts1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.reset_index(drop=True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_useful_data(data=data, save_path=\"useful_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
